{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn. preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "# !pip install wordcloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"preprocessed-file.csv\")\n",
    "X = data['text_final']\n",
    "Y = data['tag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Y)\n",
    "# Test_Y = Encoder.fit_transform(Y)\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data['text_final'])\n",
    "X = Tfidf_vect.transform(X)\n",
    "# Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8005325587024933"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Base Learners\n",
    "l_1 = [\n",
    "                 ('rf_1', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "                 ('rf_2', KNeighborsClassifier(n_neighbors=4)),\n",
    "                 ('rf_4' , DecisionTreeClassifier(max_depth = 2)),\n",
    "                 ('rf_6' , MLPClassifier(hidden_layer_sizes=(512,256,128,64,32),\\\n",
    "                                         activation=\"relu\",random_state=1).fit(X, Train_Y))\n",
    "                ]\n",
    "l_2 = [ ('dt_2', naive_bayes.MultinomialNB()),\n",
    "       ('rf_5' , svm.SVC()) ]\n",
    "       \n",
    "second = StackingClassifier(estimators=l_2, final_estimator= LogisticRegression())\n",
    "# Create Final model by \n",
    "clf = StackingClassifier(estimators=l_1, final_estimator=second)\n",
    "# Extract score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Train_Y, stratify=Y, random_state=42)\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Modle to file in the current working directory\n",
    "\n",
    "Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf_1',\n",
       "                                RandomForestClassifier(n_estimators=10,\n",
       "                                                       random_state=42)),\n",
       "                               ('rf_2', KNeighborsClassifier(n_neighbors=4)),\n",
       "                               ('rf_4', DecisionTreeClassifier(max_depth=2)),\n",
       "                               ('rf_6',\n",
       "                                MLPClassifier(hidden_layer_sizes=(512, 256, 128,\n",
       "                                                                  64, 32),\n",
       "                                              random_state=1))],\n",
       "                   final_estimator=StackingClassifier(estimators=[('dt_2',\n",
       "                                                                   MultinomialNB()),\n",
       "                                                                  ('rf_5',\n",
       "                                                                   SVC())],\n",
       "                                                      final_estimator=LogisticRegression()))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_Model = pickle.load(file)\n",
    "\n",
    "Pickled_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
